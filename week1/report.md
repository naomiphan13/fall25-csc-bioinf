For part 1, I first cloned the repository and ran the Python script on all data sets. After that, I inspected the results and the script to understand the functionality of the algorithm. Later, I added a function in utils.py to calculate N50. Since we calculate N50, as opposed to NGA50, the results are not the same as those reported. 

Part 2 was the most challenging and time-consuming part of this assignment, as Codon is new to me. My strategy was to run the .py file using Codon, then debug each issue one by one. It was shocking to find out that Codon does not support most large libraries (yet), such as _matplotlib_ and _os_ libraries. Hence, I had to find a work-around. Fortunately, these two issues were simple. I removed the import of both libraries - fortunately enough, _matplotlib_ was not used in the original script. For _os_ library, I changed _os.path.join_ to manual string concatenation instead. 

Next, I realized that Codon cannot handle deep recursion, and _sys_ library is also not support (which is used to increase the recursion limit). Hence, I changed all recursive algorithms to iterative, including __get_depth_ and _get_longest_contig_. Last but not least, I ran into the NoneKey problem, meaning that Codon trying to access a key in dictionary that does not exist. It came at a surprise to me as Python had no problem dynamically handling this problem. This part took me an entire day to debug as I tried to figure out which key passed _None_ value. After much back and forth, I realized that the problem was not just the _None_ value, Codon is just very picky with an object's type - either you set it as _None_ or as _str_, you cannot set it as both. After the realization hits, I changed all initializations of objects to _""_ (an empty string) instead of _None_. I also added some safe handling for the problematic functions, such as __add_node, _add_arc, and __init___.

For part 3, I used _bash_ to execute the python and codon scripts automatically, given that all the data sets have been downloaded and upzipped. The script will access the directory that it is saved in, and run the Python and Codon scripts in that same directory automatically. In order to successfully run the script, the script must be saved to the same directory as all data sets and other scripts. Finally, bash will compile the final results with four columns, namely Dataset, Language, Runtime, and N50.

I was able to reproduced the same N50 numbers for data1 - data3. However, Codon procuded a much higher number for N50 compared to Python, approximately 1,000 higher. My runtime was also counterintuitive, as Codon reported longer runtime than Python for all data sets.
